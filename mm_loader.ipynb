{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "760a5845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List\n",
    "import torch\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from typing import Optional, Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88315cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "  # path\n",
    "  data_path: str = r\"D:\\Data\\Group\\2-nuclear_data\\deeplearning\"\n",
    "  \n",
    "  log_path: str = os.path.join(data_path, \"logs\")\n",
    "  \n",
    "  subjects: List[str] = field(default_factory=lambda: [\n",
    "    'NP03', 'NP04', 'NP05', \n",
    "    'NP06', 'NP07', 'NP08', \n",
    "    'NP09', 'NP10', 'NP11', \n",
    "    'NP12', 'NP13', 'NP14', \n",
    "    'NP15', 'NP16', 'NP17', \n",
    "    'NP18', 'NP19', 'NP20', \n",
    "    'NP21', 'NP22', 'NP23', \n",
    "    'NP24', 'NP25', 'NP26',\n",
    "    'NP27', 'NP28', 'NP29', \n",
    "    'NP30', 'NP31', 'NP32'])\n",
    "\n",
    "  modal_types: List[str] = field(default_factory=lambda: [\n",
    "    'eeg', \n",
    "    'ecg', \n",
    "    'eda', \n",
    "    'eye'\n",
    "  ])\n",
    "\n",
    "  # data\n",
    "  knn_k: int = 5\n",
    "  smote_seed: int = 42\n",
    "\n",
    "  # training hyper-params\n",
    "  batch_size: int = 128\n",
    "  max_epochs: int = 40\n",
    "  lr_encoder: float = 1e-3\n",
    "  lr_classifier: float = 1e-3\n",
    "  lr_domain_discriminator: float = 9e-4\n",
    "  clip_grad: float = 5.0\n",
    "\n",
    "  # MCD iterations\n",
    "  step1_iter: int = 1\n",
    "  step2_iter: int = 4\n",
    "  step3_iter: int = 1\n",
    "  lambda_GRL: float = 0.7\n",
    "\n",
    "  # mwl level\n",
    "  low_level = 1\n",
    "  mid_level = 5\n",
    "  high_level = 9\n",
    "\n",
    "  # 任务定义\n",
    "  num_classes: int = 3\n",
    "  binary_threshold: int = 6\n",
    "\n",
    "  # misc\n",
    "  device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e28ee354",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger:\n",
    "    def __init__(self, log_dir, name=__name__, log_name_prefix=\"log\", level=logging.INFO):\n",
    "        self.logger = logging.getLogger(name)\n",
    "        self.logger.setLevel(self._get_log_level(level))\n",
    "\n",
    "        self.logger.propagate = False\n",
    "        if self.logger.handlers:\n",
    "            self.logger.handlers.clear()\n",
    "\n",
    "        # 日志路径设置\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        self.log_path = os.path.join(log_dir, f\"{log_name_prefix}_{timestamp}.log\")\n",
    "\n",
    "        # 文件输出\n",
    "        file_formatter = logging.Formatter(\n",
    "            \"[{asctime}][{levelname}] {message}\",\n",
    "            datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "            style='{')\n",
    "        # file_formatter = logging.Formatter(\n",
    "        #     \"[{levelname}] {message}\",\n",
    "        #     datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "        #     style='{')\n",
    "\n",
    "        file_handler = logging.FileHandler(self.log_path, encoding='utf-8')\n",
    "        file_handler.setFormatter(file_formatter)\n",
    "        self.logger.addHandler(file_handler)\n",
    "\n",
    "        # 控制台输出\n",
    "        console_formatter = logging.Formatter(\"{message}\", style='{')\n",
    "        console_handler = logging.StreamHandler(sys.stdout)\n",
    "        console_handler.setFormatter(console_formatter)\n",
    "        self.logger.addHandler(console_handler)\n",
    "\n",
    "    def _get_log_level(self, level: str = \"INFO\") -> int:\n",
    "        if isinstance(level, int):\n",
    "            return level\n",
    "        if isinstance(level, str):\n",
    "            level = level.upper()\n",
    "            return {\n",
    "                \"DEBUG\": logging.DEBUG,\n",
    "                \"INFO\": logging.INFO,\n",
    "                \"WARNING\": logging.WARNING,\n",
    "                \"ERROR\": logging.ERROR,\n",
    "                \"CRITICAL\": logging.CRITICAL\n",
    "                }.get(level, logging.INFO)\n",
    "\n",
    "    def log(self, message: str, *args, level: str = \"INFO\", **kwargs):\n",
    "        log_level_int = self._get_log_level(level)\n",
    "        if log_level_int < self.logger.level:\n",
    "            return\n",
    "        if log_level_int >= self.logger.level:\n",
    "            try:\n",
    "                formatted_message = message.format(*args, **kwargs)\n",
    "            except Exception as e:\n",
    "                formatted_message = f\"[FormatError] {message} | Args: {args} | Kwargs: {kwargs} | Error: {e}\"\n",
    "\n",
    "        self.logger.log(log_level_int, \n",
    "                        formatted_message)\n",
    "\n",
    "    def log_metrics(self, subject_id, metrics: dict, level=\"info\"):\n",
    "        msg = f\"Subject {subject_id} |\" + \" | \".join(\n",
    "            f\"{k}: {v * 100: .2f}\" for k, v in metrics.items()\n",
    "        )\n",
    "        self.log(msg, level=level)\n",
    "\n",
    "    def save_summary(self, performance_list, metrics):\n",
    "        self.log(\"\\n=== Summary of Repetitions ===\")\n",
    "        for metric in metrics:\n",
    "            values = [perf[metric] for perf in performance_list]\n",
    "            mean = np.mean(values)\n",
    "            std = np.std(values)\n",
    "            self.log(f\"{metric.capitalize():<9}: {mean * 100:.2f}% ± {std * 100:.2f}%\")\n",
    "\n",
    "    def get_log_path(self):\n",
    "        return self.log_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6638435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelClassifier:\n",
    "    def __init__(self, \n",
    "                 low: int,\n",
    "                 mid: int,\n",
    "                 high: int,\n",
    "                 binary_threshold: int,\n",
    "                 num_classes: int):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        self.num_classes = num_classes\n",
    "        self.low_start = low\n",
    "        self.mid_start = mid\n",
    "        self.high_start = high\n",
    "        self.binary_threshold = binary_threshold\n",
    "        \n",
    "    def classify(self, rating):\n",
    "        \"\"\"\n",
    "        将单个标签值分类为 0/1/2。\n",
    "        :param x: 单个 MWL_Rating 值\n",
    "        :return: 类别标签 0/1/2\n",
    "        \"\"\"\n",
    "        if self.num_classes == 3:\n",
    "            if rating < self.mid_start:\n",
    "                return 0\n",
    "            elif self.mid_start <= rating < self.high_start:\n",
    "                return 1\n",
    "            else:\n",
    "                return 2\n",
    "        elif self.num_classes == 2:\n",
    "            if rating <= self.binary_threshold:\n",
    "                return 0\n",
    "            else:\n",
    "                return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5272f998",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalLoader:\n",
    "  def __init__(self, cfg: Config, logger: Logger, lbl_classifier: LabelClassifier):\n",
    "    self.cfg = cfg\n",
    "    self.logger = logger\n",
    "    self.lbl_classifier = lbl_classifier\n",
    "\n",
    "  def LoadMultimodalData(self) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    加载多模态数据，处理缺失模态\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    for subject in self.cfg.subjects:\n",
    "      data = self._loadSubjectData(subject)\n",
    "      if data is not None:\n",
    "        all_data.append(data)\n",
    "    \n",
    "    if not all_data:\n",
    "        raise ValueError(\"cannot load any subject data\")\n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "  def _loadSubjectData(self, subject: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    加载单个被试的数据\n",
    "    \"\"\"\n",
    "    subject_data: Dict[str, pd.DataFrame] = {}\n",
    "    available_modal_types: List[str] = []\n",
    "\n",
    "    for modal_type in self.cfg.modal_types:\n",
    "      file_path = f'{self.cfg.data_path}/{subject}/20width-4step/combined_{modal_type}_features.csv'\n",
    "      try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        if 'relative_time' not in data.columns or 'MWL_Rating' not in data.columns:\n",
    "          self.logger.log(\"No relative_time or MWL_Rating column in [subject: {}] data\", \n",
    "                          subject, level=\"WARNING\")\n",
    "          continue\n",
    "        subject_data[modal_type] = data\n",
    "        available_modal_types.append(modal_type)\n",
    "      except FileNotFoundError:\n",
    "        self.logger.log(\"Missing file for subject: {} modal type: {}\", subject, modal_type)\n",
    "        continue\n",
    "    \n",
    "    if not available_modal_types:\n",
    "      self.logger.log(\"No available modal type for subject: {}\", subject)\n",
    "      return None\n",
    "    \n",
    "    combined_data = self._combineModalities(subject_data, available_modal_types, subject)\n",
    "    self.logger.log(\"Merged subject {}: all features shape={}\", subject, combined_data.shape, level=\"INFO\")\n",
    "    return combined_data\n",
    "\n",
    "  def _combineModalities(self, subject_data: Dict, avail_model_type: List[str], subject: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    合并多模态数据\n",
    "    \"\"\"\n",
    "    # [收集时间戳]\n",
    "    tol = 3.0\n",
    "    all_timestamp = sorted({t for df in subject_data.values() for t in df['relative_time'].dropna()})\n",
    "    base_times = []\n",
    "    if all_timestamp:\n",
    "      rep = all_timestamp[0]\n",
    "      base_times.append(rep)\n",
    "      for t in all_timestamp[1:]:\n",
    "        if t - rep > tol:\n",
    "          rep = t\n",
    "          base_times.append(rep)\n",
    "    total_features = pd.DataFrame({'relative_time': base_times})\n",
    "\n",
    "    if not all_timestamp:\n",
    "      raise ValueError(\"No timestamp found in [subject: {}] data\", subject)\n",
    "    \n",
    "    # [合并特征]\n",
    "    features = []\n",
    "    for modal_type in self.cfg.modal_types:\n",
    "      if modal_type in avail_model_type:\n",
    "        df = subject_data[modal_type]\n",
    "        feature_cols = [col for col in df.columns if col not in ['relative_time', 'MWL_Rating']]\n",
    "        if len(feature_cols) == 0:\n",
    "          continue\n",
    "        block = df[['relative_time'] + feature_cols].copy()\n",
    "        block = block.rename(columns={col: f\"{modal_type}_{col}\" for col in feature_cols})\n",
    "        features.append(block)\n",
    "    for block in features:\n",
    "      # total_features = total_features.merge(block, on='relative_time', how='left')\n",
    "      total_features = pd.merge_asof(total_features,\n",
    "                                     block, \n",
    "                                     on='relative_time', \n",
    "                                     direction='backward', \n",
    "                                     tolerance=tol)\n",
    "    \n",
    "\n",
    "    # [合并标签数据]\n",
    "    labels = []\n",
    "    for modal_type in self.cfg.modal_types:\n",
    "      if modal_type in avail_model_type and \\\n",
    "        modal_type in subject_data and \\\n",
    "        'MWL_Rating' in subject_data[modal_type].columns:\n",
    "          labels.append(\n",
    "            subject_data[modal_type][['relative_time', 'MWL_Rating']]\n",
    "            .rename(columns={'MWL_Rating': f'MWL_Rating__{modal_type}'}))\n",
    "      \n",
    "    if labels:\n",
    "      lbl = labels[0]\n",
    "      for extra in labels[1:]:\n",
    "        lbl = lbl.merge(extra, on='relative_time', how='outer')\n",
    "      label_cols = [c for c in lbl.columns if c.startswith('MWL_Rating__')]\n",
    "      lbl['MWL_Rating'] = lbl[label_cols].bfill(axis=1).ffill(axis=1).iloc[:, 0]\n",
    "      lbl = lbl[['relative_time', 'MWL_Rating']]\n",
    "      total_features = total_features.merge(lbl, on='relative_time', how='left')\n",
    "      total_features['MWL_Rating'] = total_features['MWL_Rating'].ffill().bfill()\n",
    "    else:\n",
    "      total_features['MWL_Rating'] = np.nan\n",
    "\n",
    "    features_only = [c for c in total_features.columns if c not in ['relative_time', 'MWL_Rating']]\n",
    "    total_features[features_only] = total_features[features_only].fillna(0)\n",
    "    # [三分类]\n",
    "    # classifier = LabelClassifier(self.cfg.low_level, \n",
    "    #                              self.cfg.mid_level, \n",
    "    #                              self.cfg.high_level, \n",
    "    #                              self.cfg.binary_threshold, \n",
    "    #                              self.cfg.num_classes)\n",
    "    total_features['MWL_Rating'] = total_features['MWL_Rating'].apply(self.lbl_classifier.classify)\n",
    "\n",
    "    total_features['subject_id'] = subject\n",
    "    total_features = total_features.sort_values(by='relative_time').reset_index(drop=True)\n",
    "    total_features = total_features.drop_duplicates(subset=features_only, keep='first')\n",
    "    self.logger.log(\"Success to combine modalities for subject: {}, shape: {}\", \n",
    "                    subject, total_features.shape, level=\"INFO\")\n",
    "    return total_features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ccb810f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()\n",
    "logger = Logger(cfg.log_path)\n",
    "lbl_classifier = LabelClassifier(cfg.low_level, \n",
    "                                 cfg.mid_level, \n",
    "                                 cfg.high_level, \n",
    "                                 cfg.binary_threshold,\n",
    "                                 cfg.num_classes)\n",
    "mm_data = MultimodalLoader(cfg, logger, lbl_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88a0900a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP03, shape: (1623, 495)\n",
      "Merged subject NP03: all features shape=(1623, 495)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP04, shape: (1546, 495)\n",
      "Merged subject NP04: all features shape=(1546, 495)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n",
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP05, shape: (1650, 495)\n",
      "Merged subject NP05: all features shape=(1650, 495)\n",
      "Success to combine modalities for subject: NP06, shape: (1427, 495)\n",
      "Merged subject NP06: all features shape=(1427, 495)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP07, shape: (1532, 495)\n",
      "Merged subject NP07: all features shape=(1532, 495)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP08, shape: (1527, 495)\n",
      "Merged subject NP08: all features shape=(1527, 495)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP09, shape: (1732, 495)\n",
      "Merged subject NP09: all features shape=(1732, 495)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n",
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP10, shape: (1723, 495)\n",
      "Merged subject NP10: all features shape=(1723, 495)\n",
      "Success to combine modalities for subject: NP11, shape: (1678, 495)\n",
      "Merged subject NP11: all features shape=(1678, 495)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP12, shape: (1653, 495)\n",
      "Merged subject NP12: all features shape=(1653, 495)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP13, shape: (1715, 495)\n",
      "Merged subject NP13: all features shape=(1715, 495)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP14, shape: (1657, 495)\n",
      "Merged subject NP14: all features shape=(1657, 495)\n",
      "Missing file for subject: NP15 modal type: eye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP15, shape: (1758, 483)\n",
      "Merged subject NP15: all features shape=(1758, 483)\n",
      "Missing file for subject: NP16 modal type: eye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP16, shape: (1714, 483)\n",
      "Merged subject NP16: all features shape=(1714, 483)\n",
      "Missing file for subject: NP17 modal type: eye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP17, shape: (1732, 483)\n",
      "Merged subject NP17: all features shape=(1732, 483)\n",
      "Missing file for subject: NP18 modal type: eye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP18, shape: (1710, 483)\n",
      "Merged subject NP18: all features shape=(1710, 483)\n",
      "Missing file for subject: NP19 modal type: eye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP19, shape: (1567, 483)\n",
      "Merged subject NP19: all features shape=(1567, 483)\n",
      "Missing file for subject: NP20 modal type: eye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP20, shape: (1562, 483)\n",
      "Merged subject NP20: all features shape=(1562, 483)\n",
      "Missing file for subject: NP21 modal type: eye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP21, shape: (1343, 483)\n",
      "Merged subject NP21: all features shape=(1343, 483)\n",
      "Missing file for subject: NP22 modal type: eye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n",
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP22, shape: (1714, 483)\n",
      "Merged subject NP22: all features shape=(1714, 483)\n",
      "Missing file for subject: NP23 modal type: eye\n",
      "Success to combine modalities for subject: NP23, shape: (1653, 483)\n",
      "Merged subject NP23: all features shape=(1653, 483)\n",
      "Missing file for subject: NP24 modal type: eye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP24, shape: (1745, 483)\n",
      "Merged subject NP24: all features shape=(1745, 483)\n",
      "Missing file for subject: NP25 modal type: eye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n",
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP25, shape: (1657, 483)\n",
      "Merged subject NP25: all features shape=(1657, 483)\n",
      "Missing file for subject: NP26 modal type: eye\n",
      "Success to combine modalities for subject: NP26, shape: (1805, 483)\n",
      "Merged subject NP26: all features shape=(1805, 483)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP27, shape: (1746, 495)\n",
      "Merged subject NP27: all features shape=(1746, 495)\n",
      "Missing file for subject: NP28 modal type: eye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP28, shape: (1672, 483)\n",
      "Merged subject NP28: all features shape=(1672, 483)\n",
      "Missing file for subject: NP29 modal type: eye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP29, shape: (1663, 483)\n",
      "Merged subject NP29: all features shape=(1663, 483)\n",
      "Missing file for subject: NP30 modal type: eye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP30, shape: (1425, 483)\n",
      "Merged subject NP30: all features shape=(1425, 483)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP31, shape: (1747, 495)\n",
      "Merged subject NP31: all features shape=(1747, 495)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to combine modalities for subject: NP32, shape: (1651, 495)\n",
      "Merged subject NP32: all features shape=(1651, 495)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\happiness\\AppData\\Local\\Temp\\ipykernel_35240\\1540402118.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  total_features['subject_id'] = subject\n"
     ]
    }
   ],
   "source": [
    "total_data = mm_data.LoadMultimodalData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f403343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_time</th>\n",
       "      <th>eeg_Fp1_delta_PSD</th>\n",
       "      <th>eeg_Fp1_theta_PSD</th>\n",
       "      <th>eeg_Fp1_alpha_PSD</th>\n",
       "      <th>eeg_Fp1_beta_PSD</th>\n",
       "      <th>eeg_Fpz_delta_PSD</th>\n",
       "      <th>eeg_Fpz_theta_PSD</th>\n",
       "      <th>eeg_Fpz_alpha_PSD</th>\n",
       "      <th>eeg_Fpz_beta_PSD</th>\n",
       "      <th>eeg_Fp2_delta_PSD</th>\n",
       "      <th>...</th>\n",
       "      <th>eye_Saccade_Duration</th>\n",
       "      <th>eye_Saccade_Frequency</th>\n",
       "      <th>eye_Avg_Velocity_Count</th>\n",
       "      <th>eye_Avg_Velocity</th>\n",
       "      <th>eye_Saccade_Amplitude_Count</th>\n",
       "      <th>eye_Avg_Saccade_Amplitude</th>\n",
       "      <th>eye_Avg_Amplitude</th>\n",
       "      <th>eye_Avg_Pupil_Diameter</th>\n",
       "      <th>MWL_Rating</th>\n",
       "      <th>subject_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150.000</td>\n",
       "      <td>119284.967383</td>\n",
       "      <td>3187.071067</td>\n",
       "      <td>209.955324</td>\n",
       "      <td>21.815460</td>\n",
       "      <td>122016.744454</td>\n",
       "      <td>3250.179139</td>\n",
       "      <td>195.643888</td>\n",
       "      <td>24.244840</td>\n",
       "      <td>122585.845195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>NP03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154.000</td>\n",
       "      <td>60004.291996</td>\n",
       "      <td>2103.637583</td>\n",
       "      <td>169.341553</td>\n",
       "      <td>12.376694</td>\n",
       "      <td>60492.269850</td>\n",
       "      <td>2180.295764</td>\n",
       "      <td>172.240027</td>\n",
       "      <td>14.045738</td>\n",
       "      <td>63001.775268</td>\n",
       "      <td>...</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.610630</td>\n",
       "      <td>33.0</td>\n",
       "      <td>210.169394</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.532857</td>\n",
       "      <td>6.532857</td>\n",
       "      <td>3.152475</td>\n",
       "      <td>1</td>\n",
       "      <td>NP03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>158.000</td>\n",
       "      <td>59507.427397</td>\n",
       "      <td>3207.667219</td>\n",
       "      <td>238.766322</td>\n",
       "      <td>14.656701</td>\n",
       "      <td>59458.503479</td>\n",
       "      <td>3335.313952</td>\n",
       "      <td>256.375639</td>\n",
       "      <td>16.397078</td>\n",
       "      <td>61927.499552</td>\n",
       "      <td>...</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.672665</td>\n",
       "      <td>34.0</td>\n",
       "      <td>226.257647</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.468000</td>\n",
       "      <td>5.468000</td>\n",
       "      <td>3.166479</td>\n",
       "      <td>1</td>\n",
       "      <td>NP03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162.000</td>\n",
       "      <td>97356.887970</td>\n",
       "      <td>5163.942438</td>\n",
       "      <td>363.664856</td>\n",
       "      <td>26.030363</td>\n",
       "      <td>97603.409333</td>\n",
       "      <td>5256.477830</td>\n",
       "      <td>386.907906</td>\n",
       "      <td>28.141836</td>\n",
       "      <td>100218.774038</td>\n",
       "      <td>...</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.849093</td>\n",
       "      <td>37.0</td>\n",
       "      <td>208.760541</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.366667</td>\n",
       "      <td>6.366667</td>\n",
       "      <td>3.129368</td>\n",
       "      <td>1</td>\n",
       "      <td>NP03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166.000</td>\n",
       "      <td>58192.279293</td>\n",
       "      <td>3087.346277</td>\n",
       "      <td>201.488797</td>\n",
       "      <td>17.094732</td>\n",
       "      <td>58435.380151</td>\n",
       "      <td>3088.646130</td>\n",
       "      <td>213.624687</td>\n",
       "      <td>18.858007</td>\n",
       "      <td>60903.466550</td>\n",
       "      <td>...</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.797484</td>\n",
       "      <td>37.0</td>\n",
       "      <td>203.598108</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.961667</td>\n",
       "      <td>5.961667</td>\n",
       "      <td>3.143987</td>\n",
       "      <td>1</td>\n",
       "      <td>NP03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49322</th>\n",
       "      <td>13060.618</td>\n",
       "      <td>141.725367</td>\n",
       "      <td>23.649767</td>\n",
       "      <td>5.054168</td>\n",
       "      <td>2.354176</td>\n",
       "      <td>396.197326</td>\n",
       "      <td>27.122484</td>\n",
       "      <td>5.961487</td>\n",
       "      <td>2.594063</td>\n",
       "      <td>1237.124431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NP32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49323</th>\n",
       "      <td>13064.618</td>\n",
       "      <td>371.677870</td>\n",
       "      <td>60.445750</td>\n",
       "      <td>8.270844</td>\n",
       "      <td>3.613309</td>\n",
       "      <td>406.689014</td>\n",
       "      <td>75.311848</td>\n",
       "      <td>9.681655</td>\n",
       "      <td>3.702077</td>\n",
       "      <td>845.847998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NP32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49324</th>\n",
       "      <td>13068.618</td>\n",
       "      <td>488.161669</td>\n",
       "      <td>63.473177</td>\n",
       "      <td>7.949261</td>\n",
       "      <td>3.592574</td>\n",
       "      <td>523.549268</td>\n",
       "      <td>73.263961</td>\n",
       "      <td>9.168316</td>\n",
       "      <td>3.792235</td>\n",
       "      <td>1174.196092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NP32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49325</th>\n",
       "      <td>13072.618</td>\n",
       "      <td>240.336572</td>\n",
       "      <td>25.269240</td>\n",
       "      <td>4.280280</td>\n",
       "      <td>1.867680</td>\n",
       "      <td>270.665617</td>\n",
       "      <td>30.763740</td>\n",
       "      <td>5.699906</td>\n",
       "      <td>2.156052</td>\n",
       "      <td>616.544041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NP32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49326</th>\n",
       "      <td>13076.618</td>\n",
       "      <td>194.135450</td>\n",
       "      <td>20.947151</td>\n",
       "      <td>4.619729</td>\n",
       "      <td>1.661098</td>\n",
       "      <td>914.821434</td>\n",
       "      <td>35.583411</td>\n",
       "      <td>5.980538</td>\n",
       "      <td>2.300960</td>\n",
       "      <td>2230.639300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NP32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49327 rows × 495 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       relative_time  eeg_Fp1_delta_PSD  eeg_Fp1_theta_PSD  eeg_Fp1_alpha_PSD  \\\n",
       "0            150.000      119284.967383        3187.071067         209.955324   \n",
       "1            154.000       60004.291996        2103.637583         169.341553   \n",
       "2            158.000       59507.427397        3207.667219         238.766322   \n",
       "3            162.000       97356.887970        5163.942438         363.664856   \n",
       "4            166.000       58192.279293        3087.346277         201.488797   \n",
       "...              ...                ...                ...                ...   \n",
       "49322      13060.618         141.725367          23.649767           5.054168   \n",
       "49323      13064.618         371.677870          60.445750           8.270844   \n",
       "49324      13068.618         488.161669          63.473177           7.949261   \n",
       "49325      13072.618         240.336572          25.269240           4.280280   \n",
       "49326      13076.618         194.135450          20.947151           4.619729   \n",
       "\n",
       "       eeg_Fp1_beta_PSD  eeg_Fpz_delta_PSD  eeg_Fpz_theta_PSD  \\\n",
       "0             21.815460      122016.744454        3250.179139   \n",
       "1             12.376694       60492.269850        2180.295764   \n",
       "2             14.656701       59458.503479        3335.313952   \n",
       "3             26.030363       97603.409333        5256.477830   \n",
       "4             17.094732       58435.380151        3088.646130   \n",
       "...                 ...                ...                ...   \n",
       "49322          2.354176         396.197326          27.122484   \n",
       "49323          3.613309         406.689014          75.311848   \n",
       "49324          3.592574         523.549268          73.263961   \n",
       "49325          1.867680         270.665617          30.763740   \n",
       "49326          1.661098         914.821434          35.583411   \n",
       "\n",
       "       eeg_Fpz_alpha_PSD  eeg_Fpz_beta_PSD  eeg_Fp2_delta_PSD  ...  \\\n",
       "0             195.643888         24.244840      122585.845195  ...   \n",
       "1             172.240027         14.045738       63001.775268  ...   \n",
       "2             256.375639         16.397078       61927.499552  ...   \n",
       "3             386.907906         28.141836      100218.774038  ...   \n",
       "4             213.624687         18.858007       60903.466550  ...   \n",
       "...                  ...               ...                ...  ...   \n",
       "49322           5.961487          2.594063        1237.124431  ...   \n",
       "49323           9.681655          3.702077         845.847998  ...   \n",
       "49324           9.168316          3.792235        1174.196092  ...   \n",
       "49325           5.699906          2.156052         616.544041  ...   \n",
       "49326           5.980538          2.300960        2230.639300  ...   \n",
       "\n",
       "       eye_Saccade_Duration  eye_Saccade_Frequency  eye_Avg_Velocity_Count  \\\n",
       "0                      0.00               0.000000                     0.0   \n",
       "1                      1.26               1.610630                    33.0   \n",
       "2                      1.22               1.672665                    34.0   \n",
       "3                      1.24               1.849093                    37.0   \n",
       "4                      1.16               1.797484                    37.0   \n",
       "...                     ...                    ...                     ...   \n",
       "49322                  0.00               0.000000                     0.0   \n",
       "49323                  0.00               0.000000                     0.0   \n",
       "49324                  0.00               0.000000                     0.0   \n",
       "49325                  0.00               0.000000                     0.0   \n",
       "49326                  0.00               0.000000                     0.0   \n",
       "\n",
       "       eye_Avg_Velocity  eye_Saccade_Amplitude_Count  \\\n",
       "0              0.000000                          0.0   \n",
       "1            210.169394                          7.0   \n",
       "2            226.257647                          5.0   \n",
       "3            208.760541                          9.0   \n",
       "4            203.598108                         12.0   \n",
       "...                 ...                          ...   \n",
       "49322          0.000000                          0.0   \n",
       "49323          0.000000                          0.0   \n",
       "49324          0.000000                          0.0   \n",
       "49325          0.000000                          0.0   \n",
       "49326          0.000000                          0.0   \n",
       "\n",
       "       eye_Avg_Saccade_Amplitude  eye_Avg_Amplitude  eye_Avg_Pupil_Diameter  \\\n",
       "0                       0.000000           0.000000                0.000000   \n",
       "1                       6.532857           6.532857                3.152475   \n",
       "2                       5.468000           5.468000                3.166479   \n",
       "3                       6.366667           6.366667                3.129368   \n",
       "4                       5.961667           5.961667                3.143987   \n",
       "...                          ...                ...                     ...   \n",
       "49322                   0.000000           0.000000                0.000000   \n",
       "49323                   0.000000           0.000000                0.000000   \n",
       "49324                   0.000000           0.000000                0.000000   \n",
       "49325                   0.000000           0.000000                0.000000   \n",
       "49326                   0.000000           0.000000                0.000000   \n",
       "\n",
       "       MWL_Rating  subject_id  \n",
       "0               1        NP03  \n",
       "1               1        NP03  \n",
       "2               1        NP03  \n",
       "3               1        NP03  \n",
       "4               1        NP03  \n",
       "...           ...         ...  \n",
       "49322           0        NP32  \n",
       "49323           0        NP32  \n",
       "49324           0        NP32  \n",
       "49325           0        NP32  \n",
       "49326           0        NP32  \n",
       "\n",
       "[49327 rows x 495 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a6819b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
