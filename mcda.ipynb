{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12b1677e",
   "metadata": {},
   "source": [
    "### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "fcec1e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeavePOut\n",
    "from collections import Counter\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "611ff4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "  # path\n",
    "  data_path: str = r\"D:\\Data\\Group\\2-nuclear_data\\deeplearning\"\n",
    "  log_path: str = os.path.join(data_path, \"logs\")\n",
    "  subjects: List[str] = field(default_factory=lambda: [\n",
    "    'NP03', 'NP04', 'NP05', \n",
    "    'NP06', 'NP07', 'NP08', \n",
    "    'NP09', 'NP10', 'NP11', \n",
    "    'NP12', 'NP13', 'NP14', \n",
    "    'NP15', 'NP16', 'NP17', \n",
    "    'NP18', 'NP19', 'NP20', \n",
    "    'NP21', 'NP22', 'NP23', \n",
    "    'NP24', 'NP25', 'NP26',\n",
    "    'NP27', 'NP28', 'NP29', \n",
    "    'NP30', 'NP31', 'NP32'])\n",
    "  \n",
    "  # data\n",
    "  knn_k: int = 5\n",
    "  smote_seed: int = 42\n",
    "\n",
    "  # training hyper-params\n",
    "  batch_size: int = 64\n",
    "  max_epochs: int = 1\n",
    "  lr_encoder: float = 1e-3\n",
    "  lr_classifier: float = 1e-3\n",
    "  lr_domain_discriminator: float = 1e-5\n",
    "  clip_grad: float = 5.0\n",
    "\n",
    "  # MCD iterations\n",
    "  step1_iter: int = 1\n",
    "  step2_iter: int = 4\n",
    "  step3_iter: int = 1\n",
    "  # step4_iter: int = 1\n",
    "  lambda_GRL: float = 1.0\n",
    "\n",
    "  # mwl level\n",
    "  low_level = 1\n",
    "  mid_level = 5\n",
    "  high_level = 9\n",
    "\n",
    "  # 任务定义\n",
    "  num_classes: int = 3\n",
    "  binary_threshold: int = 6\n",
    "\n",
    "  # misc\n",
    "  device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f07771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_by_rest_state(df: pd.DataFrame,\n",
    "                            rest_duration_minutes: int,\n",
    "                            sampling_rate: int,\n",
    "                            label_column: str = 'MWL_Rating') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    基于实验开始前静息阶段进行 Z-score 标准化。\n",
    "\n",
    "    参数：\n",
    "    - df: DataFrame，包含按时间顺序排列的模态特征与标签\n",
    "    - rest_duration_minutes: 静息阶段时长（分钟）\n",
    "    - sampling_rate: 数据采样频率（每秒多少行）\n",
    "    - label_column: 标签列名，默认是 'MWL_Rating'\n",
    "\n",
    "    返回：\n",
    "    - 标准化后的 DataFrame（标签列保持不变）\n",
    "    \"\"\"\n",
    "    # 静息阶段数据行数\n",
    "    rest_rows = rest_duration_minutes * 60 * sampling_rate\n",
    "    # 分离标签\n",
    "    features = df.drop(columns=label_column)\n",
    "    labels = df[label_column]\n",
    "\n",
    "    # 计算静息状态下每个特征的均值和标准差\n",
    "    rest_means = features.iloc[:rest_rows].mean()\n",
    "    rest_stds = features.iloc[:rest_rows].std()\n",
    "\n",
    "    # 防止除以0\n",
    "    rest_stds[rest_stds == 0] = 1e-8\n",
    "\n",
    "    # Z-score 标准化\n",
    "    normalized_features = (features - rest_means) / rest_stds\n",
    "    # 合并标签列\n",
    "    normalized_df = pd.concat([normalized_features, labels], axis=1)\n",
    "\n",
    "    return normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4fbbc7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelClassifier:\n",
    "    def __init__(self, \n",
    "                 cfg: Config):\n",
    "        \"\"\"\n",
    "        :param low_start: basic 模式下低负荷的起始分数\n",
    "        :param mid_start: basic 模式下中负荷的起始分数\n",
    "        :param high_start: basic 模式下高负荷的起始分数\n",
    "        \"\"\"\n",
    "        self.num_classes = cfg.num_classes\n",
    "        self.low_start = cfg.low_level\n",
    "        self.mid_start = cfg.mid_level\n",
    "        self.high_start = cfg.high_level\n",
    "        self.binary_threshold = cfg.binary_threshold\n",
    "        \n",
    "    def classify(self, rating):\n",
    "        \"\"\"\n",
    "        将单个标签值分类为 0/1/2。\n",
    "        :param x: 单个 MWL_Rating 值\n",
    "        :return: 类别标签 0/1/2\n",
    "        \"\"\"\n",
    "        if self.num_classes == 3:\n",
    "            if rating < self.mid_start:\n",
    "                return 0\n",
    "            elif self.mid_start <= rating < self.high_start:\n",
    "                return 1\n",
    "            else:\n",
    "                return 2\n",
    "        elif self.num_classes == 2:\n",
    "            if rating <= self.binary_threshold:\n",
    "                return 0\n",
    "            else:\n",
    "                return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ec6ef0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eeg_data(cfg: Config):\n",
    "    \"\"\"\n",
    "    加载多个被试的 EEG 数据，并统一处理标签和添加被试编号列。\n",
    "\n",
    "    :param subjects: 被试编号列表\n",
    "    :param base_path: 基础文件路径，包含所有被试的子文件夹\n",
    "    :param low_start: 低类别最低分数\n",
    "    :param mid_start: 中类别最低分数\n",
    "    :param high_start: 高类别最低分数\n",
    "    :return: 合并后的 DataFrame\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    for subject in cfg.subjects:\n",
    "        file_path = f'{cfg.data_path}/{subject}/20width-4step/combined_eeg_features.csv'\n",
    "        df = pd.read_csv(file_path)\n",
    "        # 特征归一化\n",
    "        normalized_df = normalize_by_rest_state(df, \n",
    "                                                rest_duration_minutes=5, \n",
    "                                                sampling_rate=256)\n",
    "        # 标签分界类\n",
    "        classifier = LabelClassifier(cfg)\n",
    "        # 统一标签处理\n",
    "        normalized_df['MWL_Rating'] = \\\n",
    "            normalized_df['MWL_Rating'].apply(classifier.classify)\n",
    "        # 添加被试编号列\n",
    "        normalized_df['subject_id'] = subject\n",
    "\n",
    "        all_data.append(normalized_df)\n",
    "    # 合并所有数据并返回\n",
    "    return pd.concat(all_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fd6668",
   "metadata": {},
   "source": [
    "### function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9e42979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "da71579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = load_eeg_data(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "16d3ec91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_time</th>\n",
       "      <th>Fp1_delta_PSD</th>\n",
       "      <th>Fp1_theta_PSD</th>\n",
       "      <th>Fp1_alpha_PSD</th>\n",
       "      <th>Fp1_beta_PSD</th>\n",
       "      <th>Fpz_delta_PSD</th>\n",
       "      <th>Fpz_theta_PSD</th>\n",
       "      <th>Fpz_alpha_PSD</th>\n",
       "      <th>Fpz_beta_PSD</th>\n",
       "      <th>Fp2_delta_PSD</th>\n",
       "      <th>...</th>\n",
       "      <th>Oz_skew</th>\n",
       "      <th>Oz_kurt</th>\n",
       "      <th>O2_mean</th>\n",
       "      <th>O2_max</th>\n",
       "      <th>O2_min</th>\n",
       "      <th>O2_std</th>\n",
       "      <th>O2_skew</th>\n",
       "      <th>O2_kurt</th>\n",
       "      <th>MWL_Rating</th>\n",
       "      <th>subject_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4477</th>\n",
       "      <td>-0.636473</td>\n",
       "      <td>0.368598</td>\n",
       "      <td>-0.073809</td>\n",
       "      <td>-0.039094</td>\n",
       "      <td>0.088054</td>\n",
       "      <td>0.038874</td>\n",
       "      <td>-0.050965</td>\n",
       "      <td>-0.031509</td>\n",
       "      <td>0.035434</td>\n",
       "      <td>-0.149886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347530</td>\n",
       "      <td>-0.689563</td>\n",
       "      <td>-0.300620</td>\n",
       "      <td>0.740404</td>\n",
       "      <td>-0.059547</td>\n",
       "      <td>1.359457</td>\n",
       "      <td>0.309993</td>\n",
       "      <td>-0.546179</td>\n",
       "      <td>2</td>\n",
       "      <td>NP06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478</th>\n",
       "      <td>-0.635245</td>\n",
       "      <td>-0.013624</td>\n",
       "      <td>0.183893</td>\n",
       "      <td>0.063822</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>-0.048108</td>\n",
       "      <td>0.010177</td>\n",
       "      <td>0.076055</td>\n",
       "      <td>0.293437</td>\n",
       "      <td>-0.167018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233352</td>\n",
       "      <td>-0.702112</td>\n",
       "      <td>-1.329780</td>\n",
       "      <td>0.740404</td>\n",
       "      <td>-0.285539</td>\n",
       "      <td>1.400870</td>\n",
       "      <td>0.172236</td>\n",
       "      <td>-0.556415</td>\n",
       "      <td>2</td>\n",
       "      <td>NP06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4479</th>\n",
       "      <td>-0.634018</td>\n",
       "      <td>0.039748</td>\n",
       "      <td>0.757297</td>\n",
       "      <td>0.369634</td>\n",
       "      <td>0.192470</td>\n",
       "      <td>0.078060</td>\n",
       "      <td>0.151745</td>\n",
       "      <td>0.244125</td>\n",
       "      <td>0.589142</td>\n",
       "      <td>0.056493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364277</td>\n",
       "      <td>-0.425940</td>\n",
       "      <td>0.183650</td>\n",
       "      <td>0.740404</td>\n",
       "      <td>-0.285539</td>\n",
       "      <td>0.895392</td>\n",
       "      <td>0.207846</td>\n",
       "      <td>-0.378532</td>\n",
       "      <td>2</td>\n",
       "      <td>NP06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4480</th>\n",
       "      <td>-0.632790</td>\n",
       "      <td>-0.018267</td>\n",
       "      <td>0.450931</td>\n",
       "      <td>0.220883</td>\n",
       "      <td>0.156591</td>\n",
       "      <td>0.013175</td>\n",
       "      <td>0.054770</td>\n",
       "      <td>0.079424</td>\n",
       "      <td>0.235782</td>\n",
       "      <td>-0.143915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552443</td>\n",
       "      <td>-0.206697</td>\n",
       "      <td>0.110880</td>\n",
       "      <td>0.740404</td>\n",
       "      <td>-0.285539</td>\n",
       "      <td>0.749128</td>\n",
       "      <td>0.345080</td>\n",
       "      <td>-0.229841</td>\n",
       "      <td>2</td>\n",
       "      <td>NP06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4481</th>\n",
       "      <td>-0.631563</td>\n",
       "      <td>-0.170893</td>\n",
       "      <td>-0.187284</td>\n",
       "      <td>-0.105012</td>\n",
       "      <td>-0.006205</td>\n",
       "      <td>-0.127755</td>\n",
       "      <td>-0.102222</td>\n",
       "      <td>-0.090215</td>\n",
       "      <td>-0.044121</td>\n",
       "      <td>-0.375649</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056532</td>\n",
       "      <td>-0.376496</td>\n",
       "      <td>1.115595</td>\n",
       "      <td>0.236956</td>\n",
       "      <td>-0.285539</td>\n",
       "      <td>0.474216</td>\n",
       "      <td>-0.215024</td>\n",
       "      <td>-0.314855</td>\n",
       "      <td>2</td>\n",
       "      <td>NP06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34450</th>\n",
       "      <td>1.681945</td>\n",
       "      <td>-0.128959</td>\n",
       "      <td>-0.130031</td>\n",
       "      <td>-0.106114</td>\n",
       "      <td>-0.088398</td>\n",
       "      <td>-0.133456</td>\n",
       "      <td>-0.128618</td>\n",
       "      <td>-0.113913</td>\n",
       "      <td>-0.092718</td>\n",
       "      <td>-0.136003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191339</td>\n",
       "      <td>-0.699942</td>\n",
       "      <td>0.058455</td>\n",
       "      <td>-0.419405</td>\n",
       "      <td>0.425400</td>\n",
       "      <td>-0.366983</td>\n",
       "      <td>0.508738</td>\n",
       "      <td>-0.552424</td>\n",
       "      <td>2</td>\n",
       "      <td>NP26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34451</th>\n",
       "      <td>1.683228</td>\n",
       "      <td>-0.135220</td>\n",
       "      <td>-0.131532</td>\n",
       "      <td>-0.115955</td>\n",
       "      <td>-0.100947</td>\n",
       "      <td>-0.137345</td>\n",
       "      <td>-0.132569</td>\n",
       "      <td>-0.121037</td>\n",
       "      <td>-0.103281</td>\n",
       "      <td>-0.141468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244570</td>\n",
       "      <td>-0.666639</td>\n",
       "      <td>-0.387212</td>\n",
       "      <td>-0.419405</td>\n",
       "      <td>0.425400</td>\n",
       "      <td>-0.378538</td>\n",
       "      <td>0.562881</td>\n",
       "      <td>-0.487795</td>\n",
       "      <td>2</td>\n",
       "      <td>NP26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34452</th>\n",
       "      <td>1.684510</td>\n",
       "      <td>-0.141286</td>\n",
       "      <td>-0.134908</td>\n",
       "      <td>-0.129167</td>\n",
       "      <td>-0.126950</td>\n",
       "      <td>-0.144531</td>\n",
       "      <td>-0.140792</td>\n",
       "      <td>-0.127829</td>\n",
       "      <td>-0.122956</td>\n",
       "      <td>-0.149108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284222</td>\n",
       "      <td>-0.610701</td>\n",
       "      <td>-0.248361</td>\n",
       "      <td>-0.419405</td>\n",
       "      <td>0.425400</td>\n",
       "      <td>-0.388985</td>\n",
       "      <td>0.641565</td>\n",
       "      <td>-0.405824</td>\n",
       "      <td>2</td>\n",
       "      <td>NP26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34453</th>\n",
       "      <td>1.685792</td>\n",
       "      <td>-0.142701</td>\n",
       "      <td>-0.137163</td>\n",
       "      <td>-0.133294</td>\n",
       "      <td>-0.139431</td>\n",
       "      <td>-0.146940</td>\n",
       "      <td>-0.144777</td>\n",
       "      <td>-0.133529</td>\n",
       "      <td>-0.135186</td>\n",
       "      <td>-0.152309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202846</td>\n",
       "      <td>-0.567411</td>\n",
       "      <td>-0.256658</td>\n",
       "      <td>-0.419405</td>\n",
       "      <td>0.458089</td>\n",
       "      <td>-0.432065</td>\n",
       "      <td>0.595052</td>\n",
       "      <td>-0.325192</td>\n",
       "      <td>2</td>\n",
       "      <td>NP26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34454</th>\n",
       "      <td>1.687074</td>\n",
       "      <td>-0.146216</td>\n",
       "      <td>-0.146019</td>\n",
       "      <td>-0.133302</td>\n",
       "      <td>-0.136455</td>\n",
       "      <td>-0.150410</td>\n",
       "      <td>-0.151220</td>\n",
       "      <td>-0.138431</td>\n",
       "      <td>-0.134832</td>\n",
       "      <td>-0.155512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075666</td>\n",
       "      <td>-0.587222</td>\n",
       "      <td>0.463191</td>\n",
       "      <td>-0.419405</td>\n",
       "      <td>0.458089</td>\n",
       "      <td>-0.456244</td>\n",
       "      <td>0.695290</td>\n",
       "      <td>-0.106797</td>\n",
       "      <td>2</td>\n",
       "      <td>NP26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4449 rows × 451 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       relative_time  Fp1_delta_PSD  Fp1_theta_PSD  Fp1_alpha_PSD  \\\n",
       "4477       -0.636473       0.368598      -0.073809      -0.039094   \n",
       "4478       -0.635245      -0.013624       0.183893       0.063822   \n",
       "4479       -0.634018       0.039748       0.757297       0.369634   \n",
       "4480       -0.632790      -0.018267       0.450931       0.220883   \n",
       "4481       -0.631563      -0.170893      -0.187284      -0.105012   \n",
       "...              ...            ...            ...            ...   \n",
       "34450       1.681945      -0.128959      -0.130031      -0.106114   \n",
       "34451       1.683228      -0.135220      -0.131532      -0.115955   \n",
       "34452       1.684510      -0.141286      -0.134908      -0.129167   \n",
       "34453       1.685792      -0.142701      -0.137163      -0.133294   \n",
       "34454       1.687074      -0.146216      -0.146019      -0.133302   \n",
       "\n",
       "       Fp1_beta_PSD  Fpz_delta_PSD  Fpz_theta_PSD  Fpz_alpha_PSD  \\\n",
       "4477       0.088054       0.038874      -0.050965      -0.031509   \n",
       "4478       0.002991      -0.048108       0.010177       0.076055   \n",
       "4479       0.192470       0.078060       0.151745       0.244125   \n",
       "4480       0.156591       0.013175       0.054770       0.079424   \n",
       "4481      -0.006205      -0.127755      -0.102222      -0.090215   \n",
       "...             ...            ...            ...            ...   \n",
       "34450     -0.088398      -0.133456      -0.128618      -0.113913   \n",
       "34451     -0.100947      -0.137345      -0.132569      -0.121037   \n",
       "34452     -0.126950      -0.144531      -0.140792      -0.127829   \n",
       "34453     -0.139431      -0.146940      -0.144777      -0.133529   \n",
       "34454     -0.136455      -0.150410      -0.151220      -0.138431   \n",
       "\n",
       "       Fpz_beta_PSD  Fp2_delta_PSD  ...   Oz_skew   Oz_kurt   O2_mean  \\\n",
       "4477       0.035434      -0.149886  ...  0.347530 -0.689563 -0.300620   \n",
       "4478       0.293437      -0.167018  ...  0.233352 -0.702112 -1.329780   \n",
       "4479       0.589142       0.056493  ...  0.364277 -0.425940  0.183650   \n",
       "4480       0.235782      -0.143915  ...  0.552443 -0.206697  0.110880   \n",
       "4481      -0.044121      -0.375649  ... -0.056532 -0.376496  1.115595   \n",
       "...             ...            ...  ...       ...       ...       ...   \n",
       "34450     -0.092718      -0.136003  ...  0.191339 -0.699942  0.058455   \n",
       "34451     -0.103281      -0.141468  ...  0.244570 -0.666639 -0.387212   \n",
       "34452     -0.122956      -0.149108  ...  0.284222 -0.610701 -0.248361   \n",
       "34453     -0.135186      -0.152309  ...  0.202846 -0.567411 -0.256658   \n",
       "34454     -0.134832      -0.155512  ...  0.075666 -0.587222  0.463191   \n",
       "\n",
       "         O2_max    O2_min    O2_std   O2_skew   O2_kurt  MWL_Rating  \\\n",
       "4477   0.740404 -0.059547  1.359457  0.309993 -0.546179           2   \n",
       "4478   0.740404 -0.285539  1.400870  0.172236 -0.556415           2   \n",
       "4479   0.740404 -0.285539  0.895392  0.207846 -0.378532           2   \n",
       "4480   0.740404 -0.285539  0.749128  0.345080 -0.229841           2   \n",
       "4481   0.236956 -0.285539  0.474216 -0.215024 -0.314855           2   \n",
       "...         ...       ...       ...       ...       ...         ...   \n",
       "34450 -0.419405  0.425400 -0.366983  0.508738 -0.552424           2   \n",
       "34451 -0.419405  0.425400 -0.378538  0.562881 -0.487795           2   \n",
       "34452 -0.419405  0.425400 -0.388985  0.641565 -0.405824           2   \n",
       "34453 -0.419405  0.458089 -0.432065  0.595052 -0.325192           2   \n",
       "34454 -0.419405  0.458089 -0.456244  0.695290 -0.106797           2   \n",
       "\n",
       "       subject_id  \n",
       "4477         NP06  \n",
       "4478         NP06  \n",
       "4479         NP06  \n",
       "4480         NP06  \n",
       "4481         NP06  \n",
       "...           ...  \n",
       "34450        NP26  \n",
       "34451        NP26  \n",
       "34452        NP26  \n",
       "34453        NP26  \n",
       "34454        NP26  \n",
       "\n",
       "[4449 rows x 451 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df[full_df['MWL_Rating'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0526c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "95431d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(columns=[\"subject_id\", \"MWL_Rating\"]).values\n",
    "y = data[\"MWL_Rating\"].values\n",
    "groups = data[\"subject_id\"].values  # 被试的编号\n",
    "unique_subjects = np.unique(groups) # 取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "199c5d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape=(43792, 449), y.shape=(43792,), groups=(43792,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x.shape={x.shape}, y.shape={y.shape}, groups={groups.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9d51c5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lpo = LeavePOut(p=1)  # 留p个被试做测试集\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "all_y_prob = []\n",
    "subject_metrics = {\n",
    "    \"subject_id\": [],\n",
    "    \"accuracy\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1\": [],\n",
    "    \"auc\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "feba2149",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_index, target_index = list(lpo.split(unique_subjects))[14]\n",
    "source_subject = unique_subjects[source_index]\n",
    "target_subject = unique_subjects[target_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "94b4512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_origin, y_train_origin = x[np.isin(groups, source_subject)], y[np.isin(groups, source_subject)]\n",
    "x_test, y_test = x[np.isin(groups, target_subject)], y[np.isin(groups, target_subject)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4b3ba81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42367, 449) (42367,)\n",
      "2.4384957519957036e-18 0.9996576736428038\n"
     ]
    }
   ],
   "source": [
    "print(x_train_origin.shape, y_train_origin.shape)\n",
    "print(np.nanmean(x_train_origin), np.nanstd(x_train_origin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1c1f602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_clean_mask = ~np.isnan(x_test).any(axis=1)\n",
    "y_test_clean_mask = ~np.isnan(y_test)\n",
    "test_clean_mask = x_test_clean_mask & y_test_clean_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "de3cf082",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test[test_clean_mask]\n",
    "y_test = y_test[test_clean_mask]\n",
    "label_counter_test = Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c7c48e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values_by_knn(x, n_neighbors=5):\n",
    "    \"\"\"\n",
    "    使用 KNN 算法填充缺失值。\n",
    "\n",
    "    :param x: 特征数据\n",
    "    :param n_neighbors: 用于 KNN 填充的邻居数量，默认为 5\n",
    "    :return: 填充后的特征数据\n",
    "    \"\"\"\n",
    "    knn_imp = KNNImputer(n_neighbors=n_neighbors)\n",
    "    x_imp = knn_imp.fit_transform(x)\n",
    "    return x_imp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "df45ce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_imputed = impute_missing_values_by_knn(x_train_origin, cfg.knn_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7d890f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.040956013531597e-06 0.9996396869009675\n"
     ]
    }
   ],
   "source": [
    "print(np.nanmean(x_train_imputed), np.nanstd(x_train_imputed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9b93235a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_imputed\n",
    "y_train = y_train_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0ec2ae77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.040956013531597e-06 0.559282926683751\n"
     ]
    }
   ],
   "source": [
    "print(np.nanmean(x_train), np.nanstd(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f8136a",
   "metadata": {},
   "source": [
    "### 对训练集和测试集的 x 进行标准化\n",
    "1. 确保所有特征能够具备相同的尺度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "651d7ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "537090b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.450304115116204e-19 1.0003704208493251\n"
     ]
    }
   ],
   "source": [
    "print(np.nanmean(x_train_scaled), np.nanstd(x_test_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d69913",
   "metadata": {},
   "source": [
    "- 添加通道维度，把每个样本的特征序列看作一个时间序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "906b815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_x = torch.tensor(x_train, dtype=torch.float32).unsqueeze(2).to(cfg.device)\n",
    "source_y = torch.tensor(y_train, dtype=torch.long).to(cfg.device)\n",
    "target_x = torch.tensor(x_test, dtype=torch.float32).unsqueeze(2).to(cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1a273fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not torch.isnan(source_x).any() and not torch.isinf(source_x).any()\n",
    "assert not torch.isnan(target_x).any() and not torch.isinf(target_x).any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "59b9dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = source_x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c157fa11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "449"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d4c05fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEncoder(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(FeatureEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=input_dim, \n",
    "                      out_channels=256, \n",
    "                      kernel_size=1, \n",
    "                      stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=256, \n",
    "                      out_channels=128, \n",
    "                      kernel_size=1, \n",
    "                      stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=128, \n",
    "                      out_channels=128, \n",
    "                      kernel_size=1, \n",
    "                      stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        features = features.squeeze(-1)  # 移除最后一个维度，变为 (batch_size, 128)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "3906badf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_e = FeatureEncoder(input_dim).to(cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "6bd6a1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv1d(449, 256, kernel_size=(1,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
       "    (3): ReLU()\n",
       "    (4): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "    (5): ReLU()\n",
       "    (6): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2509684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    模块二：分类器\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 feature_dim_1, \n",
    "                 feature_dim_2, \n",
    "                 feature_dim_3, \n",
    "                 num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(feature_dim_1, \n",
    "                      feature_dim_2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(feature_dim_2, \n",
    "                      feature_dim_3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(feature_dim_3, \n",
    "                      num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ff895d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_c1 = Classifier(128, 64, 32, 3).to(cfg.device)\n",
    "model_c2 = Classifier(128, 256, 128, 3).to(cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "8eca18f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_e = optim.Adam(model_e.parameters(), \n",
    "                          lr=cfg.lr_encoder,\n",
    "                          weight_decay=1e-4)\n",
    "optimizer_c1 = optim.Adam(model_c1.parameters(), \n",
    "                          lr=cfg.lr_classifier,\n",
    "                          weight_decay=1e-4)\n",
    "optimizer_c2 = optim.Adam(model_c2.parameters(), \n",
    "                          lr=cfg.lr_classifier,\n",
    "                          weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "272b70c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dataset = TensorDataset(source_x, source_y)\n",
    "source_loader = DataLoader(source_dataset, batch_size=64, shuffle=True)\n",
    "target_dataset = TensorDataset(target_x)\n",
    "target_loader = DataLoader(target_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "74e66cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossManager:\n",
    "    def __init__(self, num_classes=3):\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    @staticmethod\n",
    "    def step1_loss(out1, out2, y):\n",
    "        # 默认使用交叉熵\n",
    "        return F.cross_entropy(out1, y) + F.cross_entropy(out2, y)\n",
    "\n",
    "    # @staticmethod\n",
    "    # def discrepancy_loss(out1, out2):\n",
    "    #     return torch.mean(torch.abs(F.softmax(out1, dim=1) - F.softmax(out2, dim=1)))\n",
    "\n",
    "    def double_classifier_loss_mse(self, out1, out2, y):\n",
    "        y_onehot = torch.nn.functional.one_hot(y, num_classes=self.num_classes).float()\n",
    "        p1 = torch.softmax(out1, dim=1)\n",
    "        p2 = torch.softmax(out2, dim=1)\n",
    "        return F.mse_loss(p1, y_onehot) + F.mse_loss(p2, y_onehot)\n",
    "\n",
    "    @staticmethod\n",
    "    def double_classifier_loss_ce(p1, p2, y_true):\n",
    "        return F.cross_entropy(p1, y_true) + F.cross_entropy(p2, y_true)\n",
    "\n",
    "    # @staticmethod\n",
    "    # def mmd_loss(source, target):\n",
    "    #     batch_size = int(source.size()[0])\n",
    "    #     kernels = gaussian_kernel(source, target)\n",
    "    #     xx = kernels[:batch_size, :batch_size]\n",
    "    #     yy = kernels[batch_size:, batch_size:]\n",
    "    #     xy = kernels[:batch_size, batch_size:]\n",
    "    #     yx = kernels[batch_size:, :batch_size]\n",
    "\n",
    "    #     return torch.mean(xx + yy - xy - yx)\n",
    "    \n",
    "    def discrepancy(self, out1, out2):\n",
    "        return torch.mean(torch.abs(F.softmax(out1, dim=1) - F.softmax(out2, dim=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e7a601a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_manager = LossManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c3c0712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_loss = nn.CrossEntropyLoss()\n",
    "bce_loss = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "df35db96",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_iter = iter(source_loader)\n",
    "target_iter = iter(target_loader)\n",
    "# epoch‑level accumulators\n",
    "cls_loss_epoch = dis_max_epoch = dis_min_epoch = dom_loss_epoch = 0.0\n",
    "n_batches = len(source_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db410ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader._SingleProcessDataLoaderIter at 0x1eb3309c750>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epoch‑level accumulators\n",
    "cls_loss_epoch = dis_max_epoch = dis_min_epoch = dom_loss_epoch = 0.0\n",
    "n_batches = len(source_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "99815d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_features, source_labels = next(source_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c68bc647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_feature.shape=torch.Size([64, 449, 1]), source_labels.shape=torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print(f\"source_feature.shape={source_features.shape}, source_labels.shape={source_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "1c428db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_features, source_labels = source_features.to(cfg.device), source_labels.to(cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "34306c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_features = next(target_iter)[0]\n",
    "target_features = target_features.to(cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f50008ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_features.shape=torch.Size([64, 449, 1])\n"
     ]
    }
   ],
   "source": [
    "print(f\"target_features.shape={target_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea071f8",
   "metadata": {},
   "source": [
    "### step-1: 源域分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "7915f8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_e.train()\n",
    "model_c1.train()\n",
    "model_c2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "b8c78f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_extract_by_e = model_e(source_features)\n",
    "p1_source, p2_source = model_c1(features_extract_by_e), model_c2(features_extract_by_e)\n",
    "# loss_cls = ce_loss(p1_source, source_labels) + ce_loss(p2_source, source_labels)\n",
    "loss_cls = loss_manager.double_classifier_loss_ce(p1_source, p2_source, source_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "ec36f9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_e.zero_grad()\n",
    "optimizer_c1.zero_grad()\n",
    "optimizer_c2.zero_grad()\n",
    "loss_cls.backward()\n",
    "optimizer_e.step()\n",
    "optimizer_c1.step()\n",
    "optimizer_c2.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "9a758c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0981, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_cls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e78fd7",
   "metadata": {},
   "source": [
    "### step-2: 最大化分类器差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "de9505c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_e.eval()\n",
    "model_c1.train()\n",
    "model_c2.train()\n",
    "# 将 step 2 修改为纯粹的对抗，避免因损失函数过于复杂而导致训练不稳定\n",
    "with torch.no_grad():\n",
    "    f_t = model_e(target_features)\n",
    "p1_t = model_c1(f_t)\n",
    "p2_t = model_c2(f_t)\n",
    "loss_dis_max = -loss_manager.discrepancy(p1_t, p2_t)\n",
    "\n",
    "optimizer_c1.zero_grad()\n",
    "optimizer_c2.zero_grad()\n",
    "loss_dis_max.backward()\n",
    "optimizer_c1.step()\n",
    "optimizer_c2.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5abf741",
   "metadata": {},
   "source": [
    "### 最小化分类器差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "7b417988",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_e.train()\n",
    "model_c1.eval()\n",
    "model_c2.eval()\n",
    "for _ in range(4):\n",
    "    f_t = model_e(target_features)\n",
    "    p1_t, p2_t = model_c1(f_t), model_c2(f_t)\n",
    "    loss_dis_min = loss_manager.discrepancy(p1_t, p2_t)\n",
    "    optimizer_e.zero_grad()\n",
    "    loss_dis_min.backward()\n",
    "    optimizer_e.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "b8cedd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_loss_epoch += loss_cls.item()\n",
    "dis_max_epoch += (-loss_dis_max).item()\n",
    "dis_min_epoch += loss_dis_min.item()\n",
    "# dom_loss_epoch += loss_domain.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "95d5d37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = (f\"Classification loss: {loss_cls.item():.4f}\\n\"\n",
    "       f\"Discrepancy maximization: {(-loss_dis_max).item():.4f}\\n\"\n",
    "       f\"Discrepancy minimization: {loss_dis_min.item():.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "4a6acabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification loss: 2.0981\n",
      "Discrepancy maximization: 0.0210\n",
      "Discrepancy minimization: 0.0190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67efaa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for source_features, source_labels in source_loader:\n",
    "  source_features, source_labels = source_features.to(cfg.device), source_labels.to(cfg.device)\n",
    "  features = model_e(source_features)\n",
    "  p1 = model_c1(features)\n",
    "  p2 = model_c2(features)\n",
    "  loss_cls = loss_manager.double_classifier_loss_ce(p1, p2, source_labels)\n",
    "\n",
    "  optimizer_e.zero_grad()\n",
    "  optimizer_c1.zero_grad()\n",
    "  optimizer_c2.zero_grad()\n",
    "  loss_cls.backward()\n",
    "  optimizer_e.step()\n",
    "  optimizer_c1.step()\n",
    "  optimizer_c2.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "535cd6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([63, 449, 1])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "200f1936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of target_features: <class 'torch.Tensor'>\n",
      "The type of target_features: <class 'torch.Tensor'>\n",
      "The type of target_features: <class 'torch.Tensor'>\n",
      "The type of target_features: <class 'torch.Tensor'>\n",
      "The type of target_features: <class 'torch.Tensor'>\n",
      "The type of target_features: <class 'torch.Tensor'>\n",
      "The type of target_features: <class 'torch.Tensor'>\n",
      "The type of target_features: <class 'torch.Tensor'>\n",
      "The type of target_features: <class 'torch.Tensor'>\n",
      "The type of target_features: <class 'torch.Tensor'>\n",
      "The type of target_features: <class 'torch.Tensor'>\n",
      "The type of target_features: <class 'torch.Tensor'>\n",
      "The type of target_features: <class 'torch.Tensor'>\n",
      "The type of target_features: <class 'torch.Tensor'>\n",
      "The type of target_features: <class 'torch.Tensor'>\n",
      "The type of target_features: <class 'torch.Tensor'>\n",
      "The type of target_features: <class 'torch.Tensor'>\n",
      "The type of target_features: <class 'torch.Tensor'>\n",
      "The type of target_features: <class 'torch.Tensor'>\n",
      "The type of target_features: <class 'torch.Tensor'>\n",
      "The type of target_features: <class 'torch.Tensor'>\n",
      "The type of target_features: <class 'torch.Tensor'>\n",
      "The type of target_features: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "for (target_features, ) in target_loader:\n",
    "    print(f\"The type of target_features: {type(target_features)}\")\n",
    "    target_features = target_features.to(cfg.device)\n",
    "\n",
    "    # 将 step 2 修改为纯粹的对抗，避免因损失函数过于复杂而导致训练不稳定\n",
    "    with torch.no_grad():\n",
    "        f_t = model_e(target_features)\n",
    "    p1, p2 = model_c1(f_t), model_c2(f_t)\n",
    "    loss_dis_max = -loss_manager.discrepancy(p1, p2)\n",
    "\n",
    "    optimizer_c1.zero_grad()\n",
    "    optimizer_c2.zero_grad()\n",
    "    loss_dis_max.backward()\n",
    "    optimizer_c1.step()\n",
    "    optimizer_c2.step()\n",
    "    dis_max_epoch += (-loss_dis_max).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8aae52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
